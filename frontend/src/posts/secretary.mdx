
---


# The 37% Rule: How I Learned to Stop Guessing and Start Optimizing

I stumbled onto the **Secretary Problem** when reading _Algorithms to Live By_, and it completely changed how I think about decisions under uncertainty. It turns out there's an actual strategy — a mathematically optimal one — for knowing when to stop searching and finally choose.

## The Dilemma

Imagine I’m interviewing 100 candidates for a job. I have to decide immediately after each interview whether to hire that person or move on. The catch? I can’t go back. The goal: hire the best person.

At first, this sounds hopeless. But there’s a surprisingly elegant strategy: observe the first 37% (roughly 1/e) of candidates, and then pick the next person who’s better than anyone you’ve seen before. That’s it.

This is known as the **Optimal Stopping Rule**, or the **37% Rule**.

## Trying It Myself

To really understand this, I decided to simulate it in Python. Here’s what I came up with:

```python
import math
import random

def secretary_problem(n, trials=10000):
    success = 0
    for _ in range(trials):
        candidates = list(range(1, n + 1))
        random.shuffle(candidates)

        k = math.ceil(n / math.e)
        best_in_first_k = max(candidates[:k])

        for candidate in candidates[k:]:
            if candidate > best_in_first_k:
                if candidate == n:
                    success += 1
                break
    return success / trials

n = 100
print(f"Success probability: {secretary_problem(n):.4f}")
```

After running this a few times, I kept getting around **36.8%** success — right in line with the math.

## Visualizing the Pattern

Then I got curious: how does this strategy perform across different numbers of candidates? I wrote another function to graph this:

```python
import matplotlib.pyplot as plt

def simulate_range(n_range):
    results = []
    for n in n_range:
        prob = secretary_problem(n)
        results.append(prob)
    return results

n_values = list(range(10, 201))
probs = simulate_range(n_values)

plt.figure(figsize=(12, 6))
plt.plot(n_values, probs, label='Optimal Strategy')
plt.axhline(1 / math.e, color='red', linestyle='--', label='1/e')
plt.xlabel('Number of Candidates')
plt.ylabel('Probability of Selecting the Best')
plt.title('Optimal Stopping Probability by n')
plt.legend()
plt.grid(True)
plt.show()
```

The graph shows a consistent trend toward 36.8%, confirming that this works for large `n`.

## Compared to Random Selection

If I just randomly picked a candidate, the chance of selecting the best would only be `1/n`. So for 100 candidates, that’s 1%. Using the 37% Rule gives me **36x better odds**.

```python
def random_selection(n, trials=10000):
    success = 0
    for _ in range(trials):
        candidates = list(range(1, n + 1))
        random.shuffle(candidates)
        pick = random.randint(0, n - 1)
        if candidates[pick] == n:
            success += 1
    return success / trials
```

## When I Started Seeing This Everywhere

This rule isn’t just for hiring. It works for:

- Apartment hunting
- Dating
- Deciding when to stop scrolling and commit to a movie
- Choosing the best product out of dozens

As long as the conditions apply — you can’t go back, and you see options sequentially — the 37% Rule can help.

## Final Thoughts

What struck me most is how **counterintuitive** this all is. I would have assumed more trial-and-error would work better. But the math says otherwise — the best move is to pause, observe, then act decisively.

It doesn’t guarantee success every time. But it guarantees the **best possible odds**.

And for me, that’s enough to stop guessing and start trusting the numbers.



If you liked this exploration, try adapting the simulation for your own life scenarios. The moment you do, this abstract idea becomes surprisingly real.
